{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will scrape pages from Semantics Scholar\n",
    "# I filter down to journal articles only. I also put the search term into quotation marks.\n",
    "\n",
    "# \"International Affairs\": \n",
    "# https://www.semanticscholar.org/search?publicationType%5B0%5D=JournalArticle&q=%22international%20affairs%22&sort=relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Paper_data1.csv\",\"w\",newline= \"\") as csvfile:\n",
    "    writer= csv.writer(csvfile)\n",
    "    writer.writerow([\"Title\", \"Abstract\",\"Keywords\", \"Journal\", \"Authors\", \"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the URL here!\n",
    "# I filter down to journal articles only. I also put the search term into quotation marks.\n",
    "\n",
    "url= \"https://www.semanticscholar.org/search?publicationType%5B0%5D=JournalArticle&q=%22international%20affairs%22&sort=relevance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easier to open each entry and scrape from it's full page\n",
    "# Need to script Selenium for that\n",
    "#\n",
    "# To open papers click: <a href=...   data-selenium-selector=\"title-link\">\n",
    "#\n",
    "# To expand full abstract need to click <a class=\"text-truncator__toggle mod-clickable more\" role=\"button\" \n",
    "#                                       aria-label=\"Expand truncated text\" data-selenium-selector=\"text-truncator-toggle\">\n",
    "#                                       CONTINUE READING</a>\n",
    "#\n",
    "# Then do that for each paper down the page.\n",
    "# 10 per page\n",
    "# Then can manually change pages (or automate it if can figure out how)\n",
    "# End of url is &page=2, sequential for each new page\n",
    "# Grab first 20 pages, 10 entries per page, per topic?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From each page:\n",
    "# Title will be in:<h1 data-selenium-selector=\"paper-detail-title\"></h1>\n",
    "# Abstract will be in:<div class=\"text-truncator abstract__text text--preline\">\n",
    "# Keywords will be in: <div class=\"entity-columns\" data-selenium-selector=\"entities-list\"><div class=\"flex-container flex-wrap\"><div class=\"flex-item\"><ul class=\"entity-column\">\n",
    "#                      <li class=\"entity-group-item\" data-selenium-selector=\"entity-name\" data-heap-id=\"entity_click\"><span class=\"preview-box__target\">\n",
    "#                       <div class=\"flex-item\"><ul class=\"entity-column\">\n",
    "# Journal will be in: <span data-selenium-selector=\"venue-metadata\"><span><span>New Media &amp; Society</span></span></span>\n",
    "# Authors names will be in: <a class=\"author-list__link author-list__author-name\"\n",
    "# Date will be in: <span data-selenium-selector=\"paper-year\"><span><span>2002</span></span></span>\n",
    "\n",
    "# stops at 5\n",
    "# whole thing together\n",
    "for i in range(1,6):\n",
    "    url_page= url + \"/page/\" + str(i)\n",
    "    response= requests.get(url_page)\n",
    "    time.sleep(1)\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    quotes=soup.find_all(class_=\"text\")\n",
    "    authors= soup.find_all(class_= \"author\")\n",
    "    \n",
    "    quote_list =[]\n",
    "    for quote in quotes:\n",
    "        quote_list.append(quote.text)\n",
    "\n",
    "    author_list=[]\n",
    "    for author in authors:\n",
    "        author_list.append(author.text)\n",
    "\n",
    "    source= [url_page]*len(quote_list)\n",
    "    \n",
    "    with open(\"Paper_data1.csv\", \"a\", newline= \"\") as csvfile:\n",
    "        wr =csv.writer(csvfile)\n",
    "        rows =zip(source, quote_list, author_list)\n",
    "        wr.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_page= url \n",
    "# for a later step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response= requests.get(url_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes=soup.find_all(class_=\"text\")\n",
    "authors= soup.find_all(class_= \"author\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this just tests if it works.\n",
    "#print(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This also tests if it works.\n",
    "# print(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_list =[]\n",
    "author_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for quote in quotes:\n",
    "    quote_list.append(quote.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author in authors:\n",
    "    author_list.append(author.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source= [url_page]*len(quote_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"quote_info.csv\", \"a\", newline= \"\") as csvfile:\n",
    "#     wr =csv.writer(csvfile)\n",
    "#     rows =zip(source, quote_list, author_list)\n",
    "#     wr.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This also tests if it works.\n",
    "# quote_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
